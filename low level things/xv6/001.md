* https://www.youtube.com/watch?v=KkenLT8S9Hs&list=PLP29wDx6QmW4Mw8mgvP87Zk33LRcKA9bl
* https://github.com/mit-pdos/xv6-riscv

> [!note] premessa
Si segue il progetto [xv6-riscv](https://github.com/mit-pdos/xv6-riscv), ossia una implementazione educativa di `unix v6` per `riscv`. 

Il progetto contiene un `kernel.ld`, che descrive il `layout di linking` degli oggetti

# cap 1

## `fork`, `wait` e `exit`
i processi sono creati con `fork`, ossia la duplicazione del processo. Con `exec` invece rimpiazzo l'immagine dell'eseguibile di un processo. Con `wait` posso aspettare che un figlio termini l'esecuzione, con queste 3 chiamate di sistema posso implementare una `shell` (a patto di avere una console per scrivere e leggere l'input, banalmente un'interfaccia `UART`).
con `exit` un processo termina l'esecuzione e risveglia eventualmente un processo in attesa su `wait`.


### `read` e `write` in breve
`read` e `write` operano su file, identificati da un `file descriptor`, che astraggono generalmente l'`io` (`pipe`, `device`, `file`, ecc...). Ogni processo ha una sua `file descriptor table` dove `0` e `1` sono rispettivamente standard input e standard output.

`read` e `write` hanno un `offset` interno per capire da dove iniziare a leggere e scrivere.

### `pipe`
Con `pipe` posso esporre una parte di `buffer` del `kernel` a dei processi, come una coppia di `file descriptors`: uno per leggere e uno per scrivere.

Scrivere su un lato della pipe, mi permette di leggere dall'altro lato: *posso far comunicare due processi*.
```c
int p[2];
char *argv[2];
argv[0] = "wc";
argv[1] = 0;

pipe(p);
if(fork() == 0) {
	/* figlio */
	close(0);
	dup(p[0]);
	close(p[0])
	close(p[1]);
	exec("/bin/wc", argv);
} else {
	/* padre */
	close(p[0]);
	write(p[1], "hello world\n", 12);
	close(p[1]);
}
```

- La `pipe(p)` crea due file descriptor:
    - `p[0]`: estremità **di lettura**
    - `p[1]`: estremità **di scrittura**
- Nel **figlio**, si reindirizza lo `stdin` (`fd 0`) alla lettura dalla pipe.
- Il **padre** scrive nella pipe.
- Quindi il processo `wc` (word count) legge "hello world" dal `fd 0`, che è stato rimpiazzato da `p[0]`.

 > aggiungere altre cose saltate fino al capitolo 2
# cap 2
Punti chiave sull'organizzazione del sistema:
* multi-core
* isolazione tra processi
* progettato per eseguire su `qemu`
* uso di chiamate di sistema per astrarre l'hardware
* scheduling dei processi

> nota: alcuni sistemi embedded invece che avere un `kernel` che coordina le applicazione, preferiscono un'approccio dove il `kernel` e' una libreria di procedure da chiamare, e i processi si orchestrano da soli

Ma e' conveniente eseguire tutto il kernel come un unico eseguibile (monolitico) in modalita supervisor? No, perche' un'errore puo' essere fatale ma e' progettualmente piu semplice e comunque: "basta evitare errori".

Se si vuole evitare questo approccio si opta per la struttura a `microkernel`: i servizi base del sistema operativo comunicano tramite messaggi con il `microkernel`, la parte essenziale che deve essere eseguita in modalita supervisor.

## processi
in `xv6` l'unita di isolazione e' il `processo`.
La memoria di un processo e' indirizzata tramite la mappatura delle pagine.

Organizzazione memoria (basso verso alto): 
* indirizzo `0`: user text, contente il testo del programma
* stack
* heap (usata da `malloc`)

Nella traduzione degli indirizzi, dei `64` bit che RISCV permette di usare, `39` sono usati per prelevare l'indirizzo nella pagina, e xv6 ne usa `38` di questi, quindi ogni processo puo' indirizzare al massimo da 0 fino a `2^38-1= 0x3ffffffff`, ossia `MAXVA`.

Oltre lo stack troviamo le pagine per le transizioni tra spazio utente e kernel:
* `trampoline` page (e' una pagina, quindi `4096 byte`), contiene il codice per la transizione. 
* `trapframe` page, dove sono salvati i valori dei registri

Inoltre ogni processo ha due `stack`: uno per codice utente, e uno per l'esecuzione delle `trap`. L'accesso allo stack del kernel (di proprieta del processo) e' protetto!

Quando viene eseguita una sys call tramite `ecall`, si finisce in un'area del `kernel` predefinita. Quando la chiamata e' finita, si ritorna al codice utente usando `sret`.

`p->pagetable` contiene le page table nel formato che RISC-V si aspetta

# cap 3
`xv6` esegue su `Sv39 RISC-V` quindi, i 39 bit di un indirizzo a 64-bit sono effettivamente usati

# compilare ed eseguire
Per compilare ed eseguire il sistema operativo bisogna: configurare un ambiente di cross compiling per architettura `riscv`, e installare `qemu` per emulare una cpu `riscv`.

`qemu` permette di eseguire il modello virtuale di una macchina (CPU, memoria e altri device virtuali) e di eseguire un `guest OS`.

Qualsiasi opzione, seguita da `help` genera il testo di aiuto.
```bash
qemu-system-riscv -option help
```

# analisi del boot di xv6!

```c
OUTPUT_ARCH( "riscv" )
ENTRY( _entry )

SECTIONS
{
  /*
   * ensure that entry.S / _entry is at 0x80000000,
   * where qemu's -kernel jumps.
   */
  . = 0x80000000;

	...
}
```

dove `ENRTY`: indica la funzione o simbolo per l'entrata, `quemu` si aspetta di trovarlo a `0x80000000`.

> Gli indirizzi prima di `0x80000000` servono per `i/o`

L'entrata e' banalmente definita in `entry.S`. Prima di eseguire codice `C` bisogna fare delle istruzioni in assembly per fare il setup dello `stack`.
```c
# qemu -kernel loads the kernel at 0x80000000
# and causes each hart (i.e. CPU) to jump there.
# kernel.ld causes the following code to
# be placed at 0x80000000.
.section .text
.global _entry
_entry:
        # set up a stack for C.
        # stack0 is declared in start.c,
        # with a 4096-byte stack per CPU.
        # sp = stack0 + (hartid * 4096)
        la sp, stack0
        li a0, 1024*4
        csrr a1, mhartid
        addi a1, a1, 1
        mul a0, a0, a1
        add sp, sp, a0
        # jump to start() in start.c
        call start
spin:
        j spin
```

* `.text`: indica una sezione di codice
* `.global _entry`: rendi il simbolo `_entry` visibile globalmente.
* viene applicata la formula `sp = stack0 + ((hartid + 1) * 4096)`. 
* `hartid + 1` perche' lo stack **cresce verso il basso**!
* il loop `spin` serve in caso `start` ritoni (*non dovrebbe mai accadere*)

Ogni cpu ha un suo stack, bisogna impostare i puntatori di ogni cpu in modo che non collidano. 

> Nota: `stack0` e' definito in `start.c`, ma usato anche da `entry.S`

```c
__attribute__ ((aligned (16))) char stack0[4096 * NCPU];
```

> Nota: `NCPU` e' una macro che indica il numero massimo di CPU utilizzabili. Quindi anche se ho 3 `CPU`, verra' allocato staticamente spazio per `NCPU`

La chiamata a `start` si occupa di preparare l'ambiente per l'esecuzione di codice. 

Nota che nel frattempo, ogni core della cpu sta eseguendo lo stesso codice, lo spazio di memoria e' unico e ripartito tra i core.

La cpu entra in `start` usando come stack `stack0+offset`.

In `riscv`:
* `machine mode`: posso fare quello che mi pare.
* `supervisor mode`: rischi ridotti, esecuzione sicura per il kernel, posso ancora controllare la mappatura della memoria virtuale.
* `user mode`: modalità sicura per l'esecuzione di codice normale, i normali processi utente.

In ordine, le operazioni eseguite in `start`:
* Impostare modalità `supervisor`: leggo `mstatus` con `r_mstatus`, che e' un wrapper per l'istruzione assembly: `csrr %0, mstatus` (e intuitivamente anche le altre si comportano cosi), poi modifico il valore e lo riscrivo.
* Disabilito il `paging` con `w_satp(0)`, ogni indirizzo corrisponde a quello fisico.
* tutti gli interrupt e le exception sono gestite in modalità supervisor dove`w_medeleg` sta per `machine exception deleg register`. ogni bit di questo registro indica se la delegazione avviene o no. cio' avviene similmente per `w_mideleg`. Si vuole inoltre abilitare tutti gli interrupt esterni a livello di supervisor con `w_sie`


# memoria
La memoria e' gestita in `kernel/kalloc.c`, usando una `freelist`:
```c
struct run {
	struct run *next;
};

struct {
	struct spinlock lock;
	struct run *freelist;
} kmem;
```

Per accedere alla `freelist` bisogna attendere `kmem->lock` (tramite `acquire`), poi si può leggere in sicurezza `kmem->freelist` e infine si rilascia il `lock`.

Quando una pagina e'
* **libera**: viene interpretata come una `struct run` e contiene l'indirizzo alla prossima **pagina libera**
* **allocata**: la pagina che contiene il puntatore alla prossima pagina libera, viene preparata per essere usata come buffer, e viene rimossa dalla `freelist`.

Quando un pagina viene allocata, il `kernel` la riempie con `0x05`. Questo e' un pattern riconoscibile, utile per il debugging.

## Es: aggiungere la chiamata di sistema `mfree`
Si vuole aggiungere una chiamata di sistema che ritorni la memoria libera.

Per farlo bisogna tenere conto che:
* `freelist` in `kalloc` tiene traccia dei blocchi di memoria liberi nel sistema.
* bisogna aggiungere la chiamata nel mapping
* creare un wrapper lato utente che fa la chiamata

Andiamo a scrivere la procedura nel kernel che ritorna la quantità di memoria libera, dove il ciclo `for` fa tutto:
```c
// in: kernel/kalloc.c
// Return the amount of free memory
uint64
kmfree(void) {
	struct run *r;
	uint64 free_bytes = 0;
	
	acquire(&kmem.lock);
	for(r = kmem.freelist; r; r = r->next, free_bytes += PGSIZE);
	release(&kmem.lock);
	
	return free_bytes;
}
```

Ora andiamo ad aggiungere la chiamata alla tabella delle `syscalls`. 
```c
// in: kernel/syscall.c
extern uint64 kmfree(void);
uint64 sys_mfree(void) {
	uint64 r;
	r = kmfree();
	return r;
}

static uint64 (*syscalls[])(void) = {
	...,
	[SYS_close] sys_close,
	[SYS_mfree] sys_mfree
}

// in: kernel/syscall.h
#define SYS_mfree 22
```

E infine:
```c
// in: user/user.h
int mfree(void);

// in: usys.pl
entry("mfree")
```

La prima dichiara il simbolo, la seconda invece genera tramite uno script `perl` il codice assembly per `mfree`.

Per ogni chiamata di sistema: si carica in `a7` il codice della chiamata corrispondente, si chiama `ecall` e poi `eret`.

# spinlock, console e printf
in `start.c` abilitiamo gli interrupt dovuti al clock, servono allo scheduler per capire quando interrompere i processi.

Quando avviene un interrupt:
* si entra in modalita `supervisor` e viene chiamato il vettore associato
* si salvano i registri nello stack del kernel
* si chiama `kerneltrap`
* `kerneltrap` chiama `devintr` e in caso gestisce un interrupt hardware.
* si ripristinano i registri dallo stack

> ogni cpu genera e riceve interrupt in modo indipendente dalle altre cpu.

> il vettore e' un'indirizzo verso il quale il `pc` punta quando avviene un certo evento (es: interrupt). Per ogni evento potrebbe esserci un vettore diverso

> nota: nelle versioni precedenti di `xv6` gli interrupt erano gestiti in `machine mode`. Il codice che inizializza gli interrupt e' completamente diverso da prima ma entrambe le versioni fanno piu o meno la stessa cosa.
> Se si entra in `machine mode`, allora bisogna delegare al supervisor come si e' fatto per il `boot`.

Rispetto all'implementazione in `machine mode`:
 * non c'e' bisogno di passare i dati da `mscratch a `sscratch`
 * il `pc` a cui passare e' definito in `trap.c`

Dopo aver finito di impostare i timer si puo vedere il `main`:
* se il `cpu id` e' 0, inizializzo le componenti del sistema
* le altre `cpu`  attendono che 0 abbia finito.

`volatile static int started = 0` e' il valore condiviso tra i core.

La cpu 0 inizializza la `console`, che utilizza `uart` per la comunicazione seriale: `Universal Asynchronous Receive Transmit`. Permette di leggere e scrivere su una porta e sara il nostro terminale.

La prima cosa che si fa e':
* `devsw[CONSOLE].read = consoleread`
* `devsw[CONSOLE].write = consolewrite`

Stiamo impostando un `device` virtuale per farlo usare al kernel tramite `write` e `read`.

Dobbiamo impostare un `lock` per l'accesso al buffer:
* `initlock`:  inizializza la `struct spinlock`, contiene dei dati utili per il debug.
* `consoleintr`, esegue come prima cosa `aquire(&cons.lock)`: attendo il permesso per usare le risorse della console. Se piu cpu usano contemporaneamente la console succedono cose strane (dipendenze).

> per la concorrenza: i `lock` non dovrebbero essere trattenuti per troppo tempo.

in `acquire`:
* `push_off()`: disabilitiamo interrupt, per evitare i `deadlock`. Si usa l'approccio `push/pull` perche' potrebbero essere chiamata piu push dalla stessa `cpu`.

`push_off` e `pop_off`:
```c
void
push_off(void)
{
	int old = intr_get();
	// se intr sono on, allora `old = 1`
	intr_off();

	// se ho fatto il primo push_off
	if(mycpu()->noff == 0)
		// ricorda il valore precedente
		mycpu()->interna = old;
	mycpu()->noff += 1;
}

void pop_off(void)
{
	struct cpu *c = mycpu();
	// controlla se gli interrupt sono stati riabilitati
	// prematuramente
	if(intr_get())
		panic("pop_off");
	if (c->noff < 1)
		panic("pop_off");
	c->noff -= 1;

	// riaccendi se e solo se, push_off ha impostato interna = 1
	if(c->noff == 0 && c->interna)
		intr_on();
}
```

> il deadlock si verifica per esempio, quando due cpu attendono entrambe che venga rilasciata la stessa risorsa che entrambe detengono.

> **nota**: se non ci fosse il controllo `if(noff == 0)` in `push_off`, allora perderei lo stato dell'interrupt prima di entrare in regione critica.